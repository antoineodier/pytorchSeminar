{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_CNN_de.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "slVFf-gsMG1q",
        "MZb1F6jhDVSP",
        "9b9HKfpXv7n5",
        "2WNcY2D2Cbui"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoineodier/pytorchSeminar/blob/master/04_CNN_de.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slVFf-gsMG1q",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MZb1F6jhDVSP"
      },
      "source": [
        "### Simple CNN with 1 Conv-Layer, ReLU, Max-Pooling\n",
        "1 Layers: Conv - ReLU - MaxPool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjS-Hc8HDVSP",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn  \n",
        "import torch.nn.functional as F  \n",
        "import torch.optim as optim  \n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        # nn.Sequential are like a list of modules\n",
        "        # convenient to define composite layers like this one:\n",
        "        self.layer1 = nn.Sequential( \n",
        "            # nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
        "            nn.Conv2d(1, 16, kernel_size=5, padding=2),  \n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
        "            nn.MaxPool2d(2)\n",
        "        )  \n",
        "        self.fc = nn.Linear(14*14*16, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b9HKfpXv7n5",
        "colab_type": "text"
      },
      "source": [
        "# Übung\n",
        "1. Was ist die Output-Dimension des Conv-Layers?\n",
        "2. Ergänze das Modell mit einem weiteren Conv-Layer:\n",
        " - Kernel-Size 5, Stride 1, Padding 2 und 32 Output-Channels), einer ReLU-Activation und einem Max-Pooling mit Size 2\n",
        "3. Was ist die Output-Dimension des zweiten Conv-Layers?\n",
        "4. Benutze die Accuracy-Funktion, die Trainings- und Validation-Routine aus der vorherigen Übung\n",
        "5. Trainiere das Modell auf der GPU mit der CrossEntropyLoss und dem SGD-Optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2WNcY2D2Cbui"
      },
      "source": [
        "## Fashion MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mKPeFXg8Cbui",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Konvertierung zu PyTorch Tensoren\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Download und Laden des Trainingsdatensatzes (60k)\n",
        "trainset = datasets.FashionMNIST('./FashionMNIST/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Download und Laden des Validationsdatensatzes (10k)\n",
        "validset = datasets.FashionMNIST('./FashionMNIST/', download=True, train=False, transform=transform)\n",
        "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}